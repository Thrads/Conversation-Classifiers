# Performance and Cost: 
Costs calculated based on the rates on 8 Nov 2025. 
```bash 
===========================================================================================================
Model                          Accuracy     Cross-Cat Err           Bannedâ†’Safe         Cost      
===========================================================================================================
PyTorch (safetensors)           83.77%           5.17%                     67         $  0.0000
Quantized ONNX                  83.81%           5.17%                     75         $  0.0000
Llama 3.1 8B (Groq)             40.65%          14.43%                    289         $  0.1677
GPT OSS 20B (Groq)              35.03%          17.67%                    387         $  0.2535
GPT OSS 120B (Groq)             60.52%          10.79%                    231         $  0.5071
===========================================================================================================
```


# Message Cleaning: 

Beginning with a ```records.json``` in the data folder. Example of structure: 
```json    
    "chat_id": "sample",
    "context": "sample",
    "query": "sample",
    "messages": [
      {
        "id": "sample",
        "createdAt": "sample",
        "role": "user",
        "content": "stuff"
      },
      {
        "id": "sample",
        "createdAt": "sample",
        "role": "assistant",
        "content": "stuff"
      },
      {
        "id": "sample",
        "createdAt": "sample",
        "role": "user",
        "content": "stuff"
      },
      {
        "id": "sample",
        "createdAt": "sample",
        "role": "assistant",
        "content": "stuff"
      }
    ],
    "formatted_chat": "User: stuff"
```

# Extracting chat content: 

```bash 
python src/extract_sequences.py
```

```bash 
python src/preprocess_sequences.py
```
Very simple extraction scripts. 

# Labelling
Get Gemini 2.5 Flash and GPT 4o mini lables (can be run in parallel with a simple nohup .sh script):
```bash
python src/get_gemini_flash_labels.py
```

```bash 
python src/get_gpt_4o_mini_labels.py
```

To verify labels with gemini flash run (will save a NEW json of only AGREED on samples). 

```bash 
python src/compare_and_filter.py
```
Provides some reporting/visibility on agreement rates and class breakdowns in 'true' data. 

# Training: 

For training distilBERTs and BERTs, run: 
```bash
python src/train_distilBERT.py
```
You can modify the base model you train by changing the `model_name` string in the config. To use soft labels, modify `alpha` in your .env and the `DistillationConfig` class. 


# Export as ONNX, in case autosave fails:

**DistilBERT**
```bash
python src/export_to_onnx.py --model-path models/distilbert_512_intent_classifier --output-path models/distilbert_512_intent_classifier_onnx --max-length 512 --test
```

# Evaluation: 
Runs on the `data/splits/test.json` generated by the training routine to enforce data seperation. 

```bash
python eval/compare_models.py 
```

